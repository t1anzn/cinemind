{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e06f850",
   "metadata": {},
   "source": [
    "# Database Unit Tests\n",
    "This notebook contains tests for the database functionality of CineMind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d8bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (8.3.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from pytest) (0.4.6)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest) (2.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from pytest) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest) (1.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pytest-notebook\n",
      "  Downloading pytest_notebook-0.10.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pytest>=3.5.0 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest-notebook) (8.3.5)\n",
      "Collecting attrs<23,>=19 (from pytest-notebook)\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting nbclient~=0.5.10 (from pytest-notebook)\n",
      "  Downloading nbclient-0.5.13-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting nbdime>=4 (from pytest-notebook)\n",
      "  Downloading nbdime-4.0.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting nbformat (from pytest-notebook)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting jsonschema (from pytest-notebook)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: traitlets>=5.0.0 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from nbclient~=0.5.10->pytest-notebook) (5.14.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from nbclient~=0.5.10->pytest-notebook) (8.6.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from nbclient~=0.5.10->pytest-notebook) (1.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from nbdime>=4->pytest-notebook) (0.4.6)\n",
      "Requirement already satisfied: gitpython!=2.1.4,!=2.1.5,!=2.1.6 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbdime>=4->pytest-notebook) (3.1.44)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbdime>=4->pytest-notebook) (3.1.6)\n",
      "Collecting jupyter-server (from nbdime>=4->pytest-notebook)\n",
      "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyter-server-mathjax>=0.2.2 (from nbdime>=4->pytest-notebook)\n",
      "  Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pygments in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from nbdime>=4->pytest-notebook) (2.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbdime>=4->pytest-notebook) (2.32.3)\n",
      "Requirement already satisfied: tornado in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from nbdime>=4->pytest-notebook) (6.4.2)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat->pytest-notebook)\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from nbformat->pytest-notebook) (5.7.2)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->pytest-notebook)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->pytest-notebook)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->pytest-notebook)\n",
      "  Downloading rpds_py-0.24.0-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=3.5.0->pytest-notebook) (2.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from pytest>=3.5.0->pytest-notebook) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=3.5.0->pytest-notebook) (1.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitpython!=2.1.4,!=2.1.5,!=2.1.6->nbdime>=4->pytest-notebook) (4.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2>=2.9->nbdime>=4->pytest-notebook) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from jupyter-client>=6.1.5->nbclient~=0.5.10->pytest-notebook) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from jupyter-client>=6.1.5->nbclient~=0.5.10->pytest-notebook) (26.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->pytest-notebook) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->pytest-notebook) (310)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server->nbdime>=4->pytest-notebook) (4.9.0)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbconvert>=6.4.4 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pywinpty>=2.0.1 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading pywinpty-2.0.15-cp313-cp313-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->nbdime>=4->pytest-notebook) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->nbdime>=4->pytest-notebook) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->nbdime>=4->pytest-notebook) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->nbdime>=4->pytest-notebook) (2025.1.31)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio>=3.1.0->jupyter-server->nbdime>=4->pytest-notebook) (1.3.1)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=2.1.4,!=2.1.5,!=2.1.6->nbdime>=4->pytest-notebook) (5.0.2)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook) (6.0.2)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook) (4.13.3)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\timot\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.5->nbclient~=0.5.10->pytest-notebook) (1.17.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->nbdime>=4->pytest-notebook) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server->nbdime>=4->pytest-notebook) (4.12.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\timot\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->nbdime>=4->pytest-notebook) (2.22)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server->nbdime>=4->pytest-notebook)\n",
      "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading pytest_notebook-0.10.0-py3-none-any.whl (37 kB)\n",
      "Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading nbclient-0.5.13-py3-none-any.whl (70 kB)\n",
      "Downloading nbdime-4.0.2-py3-none-any.whl (5.9 MB)\n",
      "   ---------------------------------------- 0.0/5.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.9/5.9 MB 55.6 MB/s eta 0:00:00\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.1/3.1 MB 23.4 MB/s eta 0:00:00\n",
      "Downloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.24.0-cp313-cp313-win_amd64.whl (239 kB)\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Downloading pywinpty-2.0.15-cp313-cp313-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 44.2 MB/s eta 0:00:00\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, websocket-client, webcolors, uri-template, types-python-dateutil, tinycss2, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pywinpty, python-json-logger, prometheus-client, pandocfilters, overrides, mistune, jupyterlab-pygments, jsonpointer, fqdn, defusedxml, bleach, attrs, terminado, referencing, arrow, argon2-cffi-bindings, jupyter-server-terminals, jsonschema-specifications, isoduration, argon2-cffi, jsonschema, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, jupyter-server-mathjax, nbdime, pytest-notebook\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 25.3.0\n",
      "    Uninstalling attrs-25.3.0:\n",
      "      Successfully uninstalled attrs-25.3.0\n",
      "Successfully installed argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 attrs-22.2.0 bleach-6.2.0 defusedxml-0.7.1 fastjsonschema-2.21.1 fqdn-1.5.1 isoduration-20.11.0 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-events-0.12.0 jupyter-server-2.15.0 jupyter-server-mathjax-0.2.6 jupyter-server-terminals-0.5.3 jupyterlab-pygments-0.3.0 mistune-3.1.3 nbclient-0.5.13 nbconvert-7.16.6 nbdime-4.0.2 nbformat-5.10.4 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.21.1 pytest-notebook-0.10.0 python-json-logger-3.3.0 pywinpty-2.0.15 referencing-0.36.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.24.0 send2trash-1.8.3 terminado-0.18.1 tinycss2-1.4.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wsdump.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script send2trash.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-trust.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-execute.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-events.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-dejavu.exe and jupyter-nbconvert.exe are installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-server.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts git-nbdiffdriver.exe, git-nbdifftool.exe, git-nbmergedriver.exe, git-nbmergetool.exe, hg-nbdiff.exe, hg-nbdiffweb.exe, hg-nbmerge.exe, hg-nbmergeweb.exe, nbdiff-web.exe, nbdiff.exe, nbdime.exe, nbmerge-web.exe, nbmerge.exe and nbshow.exe are installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "%pip install pytest\n",
    "%pip install pytest-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a4e16",
   "metadata": {},
   "source": [
    "## DB Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "183c5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import sqlite3\n",
    "import os \n",
    "import pytest\n",
    "\n",
    "# Add the parent directory to path for module imports \n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Path to the SQLite database file\n",
    "db_path = os.path.join('..', 'models', 'cinemind.db')\n",
    "\n",
    "# Connect to the SQLite database\n",
    "def get_db_connection():\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    conn.row_factory = sqlite3.Row # Enable access to columns by name\n",
    "    return conn\n",
    "\n",
    "# Connect to in-memory database\n",
    "def get_test_db_connection():\n",
    "    \"\"\"Create an in-memory test database with the same schema as the production DB\"\"\"\n",
    "    test_conn = sqlite3.connect(':memory:')\n",
    "    test_conn.row_factory = sqlite3.Row \n",
    "\n",
    "    # Get schema from the real database\n",
    "    prod_conn = sqlite3.connect(db_path)\n",
    "    # Important: Set row_factory for the production connection as well\n",
    "    prod_conn.row_factory = sqlite3.Row\n",
    "    cursor = prod_conn.cursor()\n",
    "\n",
    "    # Get all CREATE statements and data\n",
    "    cursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n",
    "    create_statements = cursor.fetchall()\n",
    "\n",
    "    # Create the same schema in the in-memory database\n",
    "    test_cursor = test_conn.cursor() \n",
    "    for statement in create_statements:\n",
    "        sql = statement['sql']  # Now accessing using string key works because we set row_factory\n",
    "        if sql and 'sqlite_sequence' not in sql:\n",
    "            test_cursor.execute(sql)\n",
    "    \n",
    "    # Import reference data (smaller lookup tables)\n",
    "    reference_tables = ['Genres', 'Keywords', 'Production_Countries', 'Spoken_Languages']\n",
    "    for table in reference_tables:\n",
    "        try:\n",
    "            cursor.execute(f\"SELECT * FROM {table}\")\n",
    "            rows = cursor.fetchall() \n",
    "\n",
    "            if rows: \n",
    "                # Get column names \n",
    "                columns = [column[0] for column in cursor.description]\n",
    "                placeholders = ', '.join(['?'] * len(columns))\n",
    "                column_str = ', '.join(columns)\n",
    "\n",
    "                # Insert all rows from this reference table\n",
    "                for row in rows:\n",
    "                    # Since we're using Row objects, we can access columns by name\n",
    "                    values = [row[col] for col in columns]\n",
    "                    test_cursor.execute(f\"INSERT INTO {table} ({column_str}) VALUES ({placeholders})\", values)\n",
    "\n",
    "                print(f\"✅ Imported {len(rows)} records into {table}\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"⚠️ Error importing {table}: {e}\")\n",
    "    \n",
    "    # Import a subset of movies (100 highest rated)\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT * FROM Movies\n",
    "        WHERE vote_count > 100\n",
    "        ORDER BY vote_average DESC\n",
    "        LIMIT 100\n",
    "    \"\"\")\n",
    "    movie_rows = cursor.fetchall()\n",
    "\n",
    "    if movie_rows:\n",
    "        # Get column names \n",
    "        columns = [column[0] for column in cursor.description]\n",
    "        placeholders = ', '.join(['?'] * len(columns))\n",
    "        column_str = ', '.join(columns)\n",
    "\n",
    "        for row in movie_rows:\n",
    "            # Since we're using Row objects, we can access columns by name\n",
    "            values = [row[col] for col in columns]\n",
    "            test_cursor.execute(f\"INSERT INTO Movies ({column_str}) VALUES ({placeholders})\", values)\n",
    "\n",
    "    movie_ids = [row['id'] for row in movie_rows]\n",
    "    movie_id_list = ', '.join(map(str, movie_ids))\n",
    "    print(f\"✅ Imported {len(movie_rows)} sample movies\")\n",
    "\n",
    "    # Import related data for these movies\n",
    "    related_tables = { \n",
    "        'Movie_Genre': ('movie_id',),\n",
    "        'Movies_Cast': ('movie_id',),\n",
    "        'Movie_Keywords': ('movie_id',),\n",
    "        'Movie_Production_Countries': ('movie_id',),\n",
    "        'Movie_Spoken_Languages': ('movie_id',),\n",
    "    }\n",
    "\n",
    "    # Import actors related to our movies\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT DISTINCT c.* \n",
    "        FROM Cast c\n",
    "        JOIN Movies_Cast mc ON c.actor_id = mc.actor_id\n",
    "        WHERE mc.movie_id IN ({movie_id_list})\n",
    "    \"\"\")\n",
    "    \n",
    "    cast_rows = cursor.fetchall()\n",
    "    if cast_rows:\n",
    "        # Get column names \n",
    "        columns = [column[0] for column in cursor.description]\n",
    "        placeholders = ', '.join(['?'] * len(columns))\n",
    "        column_str = ', '.join(columns)\n",
    "        \n",
    "        for row in cast_rows:\n",
    "            # Since we're using Row objects, we can access columns by name\n",
    "            values = [row[col] for col in columns]\n",
    "            test_cursor.execute(f\"INSERT INTO Cast ({column_str}) VALUES ({placeholders})\", values)\n",
    "            \n",
    "        print(f\"✅ Imported {len(cast_rows)} cast members\")\n",
    "        \n",
    "    # Import relationship data for our movies\n",
    "    for table, key_columns in related_tables.items():\n",
    "        try:\n",
    "            where_clause = ' OR '.join([f\"{col} IN ({movie_id_list})\" for col in key_columns])\n",
    "            cursor.execute(f\"SELECT * FROM {table} WHERE {where_clause}\")\n",
    "            relation_rows = cursor.fetchall()\n",
    "            \n",
    "            if relation_rows:\n",
    "                # Get column names \n",
    "                columns = [column[0] for column in cursor.description]\n",
    "                placeholders = ', '.join(['?'] * len(columns))\n",
    "                column_str = ', '.join(columns)\n",
    "                \n",
    "                for row in relation_rows:\n",
    "                    # Since we're using Row objects, we can access columns by name\n",
    "                    values = [row[col] for col in columns]\n",
    "                    test_cursor.execute(f\"INSERT INTO {table} ({column_str}) VALUES ({placeholders})\", values)\n",
    "                    \n",
    "                print(f\"✅ Imported {len(relation_rows)} records into {table}\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"⚠️ Error importing {table}: {e}\")\n",
    "    \n",
    "    prod_conn.close()\n",
    "    test_conn.commit()\n",
    "    \n",
    "    # Verify the data\n",
    "    test_cursor.execute(\"SELECT COUNT(*) AS count FROM Movies\")\n",
    "    movie_count = test_cursor.fetchone()['count']\n",
    "    \n",
    "    test_cursor.execute(\"SELECT COUNT(*) AS count FROM Cast\")\n",
    "    cast_count = test_cursor.fetchone()['count']\n",
    "    \n",
    "    print(f\"Test database ready with {movie_count} movies and {cast_count} cast members\")\n",
    "    \n",
    "    return test_conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4497655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to 'memory' to use the in-memory test database or 'main' to use the real database\n",
    "# This determines which database all tests will run against\n",
    "USE_DATABASE = 'memory'  # Options: 'main' or 'memory'\n",
    "\n",
    "# Get the appropriate database connection based on the setting\n",
    "def get_connection_for_tests():\n",
    "    \"\"\"Returns the database connection to use for tests based on the USE_DATABASE setting\"\"\"\n",
    "    if USE_DATABASE == 'memory':\n",
    "        print(\"Using in-memory test database\")\n",
    "        return get_test_db_connection()\n",
    "    else:\n",
    "        print(\"Using main database\")\n",
    "        return get_db_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36747122",
   "metadata": {},
   "source": [
    "## Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "95f564e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(test_function):\n",
    "    \"\"\" Run a single test function and display its results\"\"\"\n",
    "    print(f\"Running test: {test_function.__name__}\")\n",
    "    try:\n",
    "        # Get the database connection based on the setting\n",
    "        conn = get_connection_for_tests()\n",
    "        test_function(conn)\n",
    "        print(\"✅ Test passed!\")\n",
    "        # Close the connection after the test\n",
    "        conn.close()\n",
    "    except AssertionError as e:\n",
    "        print(f\"❌ Test failed: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during test: {str(e)}\")\n",
    "        # Print the full exception traceback for debugging\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec6ec9",
   "metadata": {},
   "source": [
    "## Database Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58511891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_database_connection(conn):\n",
    "    \"\"\" Test if we can connect to the database \"\"\"\n",
    "    assert conn is not None, \"Failed to connect to the database\"\n",
    "\n",
    "def test_query_tables(conn):\n",
    "    \"\"\"Test if we can query the database schema.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(\"Tables in database:\", tables) \n",
    "    assert len(tables) > 0, \" No tables found in the database\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01e9e1",
   "metadata": {},
   "source": [
    "## Table Structure Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6eacda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_tables_exist(conn):\n",
    "    \"\"\"Test if all expected tables exist in the database.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    # Critical tables that must always exist\n",
    "    critical_tables = ['Movies', 'Cast', 'Genres']\n",
    "\n",
    "    # Additional expected tables (can be updated as schema evolves)\n",
    "    expected_tables = [ \n",
    "        'Keywords', 'Movie_Keywords', 'Movie_Genre', 'Production_Countries', 'Movie_Production_Countries', 'Spoken_Languages', 'Movie_Spoken_Languages', 'Movies_Cast'\n",
    "    ]\n",
    "\n",
    "    system_tables = 'sqlite_sequence'\n",
    "\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall() \n",
    "    actual_tables = [table['name'] for table in tables]\n",
    "    print(f\"Actual tables in database: {actual_tables}\")\n",
    "\n",
    "    # Critical tables check - these MUST exist\n",
    "    for table in critical_tables:\n",
    "        assert table in actual_tables, f\"Critical table {table} is missing from the database.\"\n",
    "\n",
    "    # Warning for expected tables - these SHOULD exist but can be added later \n",
    "    missing_expected = [table for table in expected_tables if table not in actual_tables]\n",
    "    if missing_expected:\n",
    "        print(f\"⚠️ WARNING: Expected tables missing: {missing_expected}.\")\n",
    "\n",
    "    # Report any additional tables that are not expected\n",
    "    additional_tables = [table for table in actual_tables if table not in critical_tables and table not in expected_tables and table not in system_tables]\n",
    "    if additional_tables:\n",
    "        print(f\"ℹ️ INFO: Additional tables found: {additional_tables}\")\n",
    "        print(\"     These tables are not in the critical or expected lists.\")\n",
    "\n",
    "def test_movies_table(conn):\n",
    "    \"\"\"Test the structure of the Movies table.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    cursor.execute(\"PRAGMA table_info(Movies);\")\n",
    "    columns = cursor.fetchall() \n",
    "    column_names = [column['name'] for column in columns]\n",
    "\n",
    "    essential_columns = ['id', 'title', 'overview', 'budget', 'revenue', 'release_date', 'runtime', 'status', 'tagline', 'popularity', 'vote_average', 'vote_count', 'original_language', 'poster_url', 'backdrop_url', 'video_url', 'reviews', 'keyposter_url', 'keyvideo_url']\n",
    "\n",
    "    expected_columns = ['original_title', 'homepage']\n",
    "\n",
    "    # Test essential columns\n",
    "    for column in essential_columns:\n",
    "        assert column in column_names, f\"Essential column '{column}' is missing from the Movies table.\"\n",
    "    \n",
    "    # Report on expected columns - warns if missing\n",
    "    missing_expected = [column for column in expected_columns if column not in column_names]\n",
    "    if missing_expected:\n",
    "        print(f\"⚠️ WARNING: Expected columns missing from Movies table: {missing_expected}\")\n",
    "\n",
    "    # Report any additional columns that weren't in either list\n",
    "    additional_columns = [column for column in column_names if column not in essential_columns and column not in expected_columns]\n",
    "    if additional_columns:\n",
    "        print(f\"ℹ️ INFO: Additional columns found in Movies table: {additional_columns}\")\n",
    "\n",
    "def test_genres_table(conn):\n",
    "    \"\"\"Test the structure of the Genres table.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"PRAGMA table_info(Genres);\")\n",
    "    columns = cursor.fetchall()\n",
    "    column_names = [column['name'] for column in columns]\n",
    "\n",
    "    essential_columns = ['genre_id', 'genre_name']\n",
    "    expected_columns = []\n",
    "\n",
    "    for column in essential_columns:\n",
    "        assert column in column_names, f\"Essential column '{column}' is missing from the Genres table.\"\n",
    "    \n",
    "    # Report on expected columns - just warns if missing\n",
    "    missing_expected = [column for column in expected_columns if column not in column_names]\n",
    "    if missing_expected:\n",
    "        print(f\"⚠️ WARNING: Some expected columns are missing from Genre table: {missing_expected}\")\n",
    "\n",
    "    # Report any additional columns that weren't in either list\n",
    "    additional_columns = [column for column in column_names if column not in essential_columns and column not in expected_columns]\n",
    "    if additional_columns:   \n",
    "        print(f\"ℹ️ INFO: Additional columns found in Genres table: {additional_columns} \")\n",
    "\n",
    "def test_cast_table(conn):\n",
    "    \"\"\"Test the structure of the Cast table.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    cursor.execute(\"PRAGMA table_info(Cast);\")\n",
    "    columns = cursor.fetchall()\n",
    "    column_names = [column['name'] for column in columns]\n",
    "    \n",
    "    essential_columns = ['actor_id', 'name']\n",
    "    expected_columns = ['characters', 'gender']\n",
    "\n",
    "    # Report on expected columns\n",
    "    missing_expected = [column for column in expected_columns if column not in column_names]\n",
    "    if missing_expected:\n",
    "        print(f\"⚠️ WARNING: Some expected columns are missing from Cast table: {missing_expected}\")\n",
    "\n",
    "    # Report on any additional columns that weren't in either list\n",
    "    additional_columns = [column for column in column_names if column not in essential_columns and column not in expected_columns]\n",
    "    if additional_columns:\n",
    "        print(f\"ℹ️ INFO: Additional columns found in Cast table: {additional_columns}\")\n",
    "\n",
    "    for column in essential_columns:\n",
    "        assert column in column_names, f\"Essential column '{column} is missing from the Cast table.'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59c2f0",
   "metadata": {},
   "source": [
    "## Data Integrity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "56560253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_integrity(conn):\n",
    "    \"\"\"Test basic data integrity in the database.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if Movies table has data\n",
    "    cursor.execute(\"SELECT COUNT(*) as count FROM Movies;\")\n",
    "    movie_count = cursor.fetchone()['count']\n",
    "    assert movie_count > 0, \"No movies found in the database\"\n",
    "\n",
    "    # Check if Genres table has data\n",
    "    cursor.execute(\"SELECT COUNT(*) as count FROM Genres;\")\n",
    "    genre_count = cursor.fetchone()['count']\n",
    "    assert genre_count > 0, \"No genres found in the database\"\n",
    "\n",
    "    # Check if Cast table has data\n",
    "    cursor.execute(\"SELECT COUNT(*) as count FROM Cast;\")\n",
    "    cast_count = cursor.fetchone()['count']\n",
    "    assert cast_count > 0, \"No cast members found in the database\"\n",
    "\n",
    "    print(f\"Data counts: {movie_count} movies, {genre_count} genres, {cast_count} cast members\")\n",
    "\n",
    "def test_relationship_integrity(conn):\n",
    "    \"\"\"Test that relationships between tables are valid.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Test Movie-Genre relationship integrity\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT mg.movie_id, mg.genre_id\n",
    "    FROM Movie_Genre mg\n",
    "    LEFT JOIN Movies m ON mg.movie_id = m.id\n",
    "    LEFT JOIN Genres g ON mg.genre_id = g.genre_id\n",
    "    WHERE m.id IS NULL OR g.genre_id IS NULL\n",
    "    LIMIT 5;\n",
    "    \"\"\")\n",
    "    orphaned_genres = cursor.fetchall()\n",
    "    assert len(orphaned_genres) == 0, f\"Found {len(orphaned_genres)} orphaned movie-genre relationships\"\n",
    "\n",
    "    # Test Movie-Cast relationship integrity\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT mc.movie_id, mc.actor_id\n",
    "    FROM Movies_Cast mc\n",
    "    LEFT JOIN Movies m ON mc.movie_id = m.id\n",
    "    LEFT JOIN Cast c ON mc.actor_id = c.actor_id \n",
    "    WHERE m.id IS NULL OR c.actor_id IS NULL\n",
    "    LIMIT 5;\n",
    "    \"\"\")\n",
    "    orphaned_cast = cursor.fetchall()\n",
    "    assert len(orphaned_cast) == 0, f\"Found {len(orphaned_cast)} orphaned movie-cast relationships\"\n",
    "\n",
    "    # Test Movie-Keywords relationship integrity\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT mk.movie_id, mk.keyword_id\n",
    "    FROM Movie_Keywords mk\n",
    "    LEFT JOIN Movies m ON mk.movie_id = m.id\n",
    "    LEFT JOIN Keywords k ON mk.keyword_id = k.keyword_id\n",
    "    WHERE m.id IS NULL OR k.keyword_id IS NULL\n",
    "    LIMIT 5;\n",
    "    \"\"\")\n",
    "    orphaned_keywords = cursor.fetchall()\n",
    "    assert len(orphaned_keywords) == 0, f\"Found {len(orphaned_keywords)} orphaned movie-keywords relationships\"\n",
    "\n",
    "    # Test Movie-Production Countries relationship integrity\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT mpc.movie_id, mpc.country_id\n",
    "    FROM Movie_Production_Countries mpc\n",
    "    LEFT JOIN Movies m ON mpc.movie_id = m.id\n",
    "    LEFT JOIN Production_Countries pc ON mpc.country_id = pc.country_id\n",
    "    WHERE m.id IS NULL OR pc.country_id IS NULL\n",
    "    LIMIT 5;\n",
    "    \"\"\")\n",
    "    orphaned_countries = cursor.fetchall()\n",
    "    assert len(orphaned_countries) == 0, f\"Found {len(orphaned_countries)} orphaned movie-countries relationships\"\n",
    "    \n",
    "    # Test Movie-Spoken Languages relationship integrity\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT msl.movie_id, msl.language_id\n",
    "    FROM Movie_Spoken_Languages msl\n",
    "    LEFT JOIN Movies m ON msl.movie_id = m.id\n",
    "    LEFT JOIN Spoken_Languages sl ON msl.language_id = sl.language_id\n",
    "    WHERE m.id IS NULL OR sl.language_id IS NULL\n",
    "    LIMIT 5;\n",
    "    \"\"\")\n",
    "    orphaned_languages = cursor.fetchall()\n",
    "    assert len(orphaned_languages) == 0, f\"Found {len(orphaned_languages)} orphaned movie-languages relationships\"\n",
    "    \n",
    "    print(\"✅ All relationship tables have valid foreign keys\")\n",
    "\n",
    "def test_cardinality(conn):\n",
    "    \"\"\"Test the cardinality of many-to-many relationships.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    # Check actors who play multiple characters\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT c.name, COUNT(DISTINCT mc.movie_id) as movie_count\n",
    "        FROM Cast c\n",
    "        JOIN Movies_Cast mc ON c.actor_id = mc.actor_id \n",
    "        GROUP BY c.name\n",
    "        HAVING movie_count > 1\n",
    "        ORDER BY movie_count DESC\n",
    "        LIMIT 5;\n",
    "    \"\"\")\n",
    "\n",
    "    actors_multiple_movies = cursor.fetchall() \n",
    "    if actors_multiple_movies:\n",
    "        print(\"Actors in multiple movies (many-to-many cardinality):\")\n",
    "        for actor in actors_multiple_movies:\n",
    "            print(f\"- {actor['name']} appears in {actor['movie_count']} movies\")\n",
    "    \n",
    "    # Check movies with multiple genres\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT m.title, COUNT(mg.genre_id) as genre_count \n",
    "        FROM Movies m \n",
    "        JOIN Movie_Genre mg ON m.id = mg.movie_id \n",
    "        GROUP BY m.title \n",
    "        HAVING genre_count > 1 \n",
    "        ORDER BY genre_count DESC \n",
    "        LIMIT 5;\n",
    "    \"\"\")\n",
    "\n",
    "    movies_multiple_genres = cursor.fetchall() \n",
    "    if movies_multiple_genres:\n",
    "        print(\"\\nMovies with multiple genres (many-to-many cardinality):\")\n",
    "        for movie in movies_multiple_genres: \n",
    "            print(f\"- {movie['title']} has {movie['genre_count']} genres\")\n",
    "\n",
    "    # Test passes if we have valid many-to-many relationships\n",
    "    assert len(actors_multiple_movies) > 0, \"No actors appear in multiple movies\"\n",
    "    assert len(movies_multiple_genres) > 0, \"No movies have multiple genres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3f454",
   "metadata": {},
   "source": [
    "# Functional Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c96bcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_basic_search_functionality(conn):\n",
    "    \"\"\"Test basic search functionality across different fields.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Check if we're using the in-memory database or the main database\n",
    "    is_memory_db = USE_DATABASE == 'memory'\n",
    "    \n",
    "    # Define test cases with expected minimum results, adjusted for in-memory DB\n",
    "    search_test_cases = [\n",
    "        # For memory DB, require fewer results since it only contains a sample of movies\n",
    "        {\"field\": \"title\", \"term\": \"star\", \"min_expected\": 1 if is_memory_db else 3},\n",
    "        {\"field\": \"overview\", \"term\": \"adventure\", \"min_expected\": 2 if is_memory_db else 5},\n",
    "        {\"field\": \"tagline\", \"term\": \"life\", \"min_expected\": 1 if is_memory_db else 2}\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing basic search functionality:\")\n",
    "    print(f\"Database mode: {'In-memory sample' if is_memory_db else 'Full database'}\")\n",
    "    \n",
    "    for test_case in search_test_cases:\n",
    "        field = test_case[\"field\"]\n",
    "        term = test_case[\"term\"]\n",
    "        min_expected = test_case[\"min_expected\"]\n",
    "        \n",
    "        # Execute search query\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT id, title \n",
    "            FROM Movies \n",
    "            WHERE LOWER({field}) LIKE ? \n",
    "            LIMIT 10\n",
    "        \"\"\", (f'%{term.lower()}%',))\n",
    "        \n",
    "        results = cursor.fetchall()\n",
    "        result_count = len(results)\n",
    "        \n",
    "        print(f\"- Search for '{term}' in {field}: found {result_count} results\")\n",
    "        if result_count > 0:\n",
    "            print(f\"  Sample results: {', '.join([r['title'] for r in results[:3]])}\")\n",
    "        \n",
    "        # For in-memory DB, just check that we found any results at all if the minimum is very low\n",
    "        if is_memory_db and min_expected <= 1:\n",
    "            # Still show a warning if no results to help with debugging\n",
    "            if result_count == 0:\n",
    "                print(f\"⚠️ WARNING: No results found for '{term}' in {field} (expected at least {min_expected})\")\n",
    "        else:\n",
    "            # Do the normal assertion for full DB or higher minimums\n",
    "            assert result_count >= min_expected, f\"Expected at least {min_expected} results for '{term}' in {field}, but found {result_count}\"\n",
    "    \n",
    "    \"\"\"Test that we can filter movies by genre.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # First, get a popular genre\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT g.genre_id, g.genre_name, COUNT(mg.movie_id) as movie_count\n",
    "        FROM Genres g\n",
    "        JOIN Movie_Genre mg ON g.genre_id = mg.genre_id\n",
    "        GROUP BY g.genre_id\n",
    "        ORDER BY movie_count DESC\n",
    "        LIMIT 1;\n",
    "    \"\"\")\n",
    "    \n",
    "    genre = cursor.fetchone()\n",
    "    assert genre is not None, \"No genres with movies found\"\n",
    "    \n",
    "    genre_id = genre['genre_id']\n",
    "    genre_name = genre['genre_name']\n",
    "    \n",
    "    # Now fetch movies in this genre\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT m.id, m.title, m.release_date\n",
    "        FROM Movies m\n",
    "        JOIN Movie_Genre mg ON m.id = mg.movie_id\n",
    "        WHERE mg.genre_id = ?\n",
    "        ORDER BY m.popularity DESC\n",
    "        LIMIT 5;\n",
    "    \"\"\", (genre_id,))\n",
    "    \n",
    "    movies = cursor.fetchall()\n",
    "    \n",
    "    print(f\"Testing genre filtering for '{genre_name}' (ID: {genre_id}):\")\n",
    "    print(f\"Found {len(movies)} movies in the '{genre_name}' genre:\")\n",
    "    for movie in movies:\n",
    "        print(f\"- {movie['title']}\")\n",
    "    \n",
    "    assert len(movies) > 0, f\"No movies found in the '{genre_name}' genre\"\n",
    "\n",
    "def test_advanced_search_capabilities(conn):\n",
    "    \"\"\"Test more complex search capabilities with multiple criteria.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"Testing advanced search functionality:\")\n",
    "    \n",
    "    # Test 1: Search for high-rated movies in a specific year range\n",
    "    min_rating = 7.5\n",
    "    start_year = \"2010\"\n",
    "    end_year = \"2020\"\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT id, title, vote_average, release_date\n",
    "        FROM Movies\n",
    "        WHERE vote_average >= ?\n",
    "          AND release_date >= ?\n",
    "          AND release_date <= ?\n",
    "        ORDER BY vote_average DESC\n",
    "        LIMIT 5\n",
    "    \"\"\", (min_rating, f\"{start_year}-01-01\", f\"{end_year}-12-31\"))\n",
    "    \n",
    "    results = cursor.fetchall()\n",
    "    print(f\"- High-rated movies ({min_rating}+) from {start_year}-{end_year}:\")\n",
    "    for movie in results:\n",
    "        release_year = movie['release_date'][:4] if movie['release_date'] else \"Unknown\"\n",
    "        print(f\"  • {movie['title']} ({release_year}) - Rating: {movie['vote_average']}\")\n",
    "    \n",
    "    assert len(results) > 0, \"No high-rated movies found in the specified date range\"\n",
    "    \n",
    "    # Test 2: Search for movies within budget range\n",
    "    min_budget = 100000000  # 100M\n",
    "    max_budget = 200000000  # 200M\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT id, title, budget\n",
    "        FROM Movies\n",
    "        WHERE budget BETWEEN ? AND ?\n",
    "        ORDER BY budget DESC\n",
    "        LIMIT 10\n",
    "    \"\"\", (min_budget, max_budget))\n",
    "    \n",
    "    results = cursor.fetchall()\n",
    "    print(f\"\\n- Movies with budget between ${min_budget/1000000}M and ${max_budget/1000000}M:\")\n",
    "    for movie in results:\n",
    "        print(f\"  • {movie['title']} - Budget: ${movie['budget']:,}\")\n",
    "    \n",
    "    assert len(results) > 0, \"No movies found in the specified budget range\"\n",
    "\n",
    "def test_genre_based_queries(conn):\n",
    "    \"\"\"Test queries related to movie genres.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    print(\"Testing genre-based queries:\")\n",
    "\n",
    "    # Test 1: Find most popular genres by movie count\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT g.genre_name, COUNT(mg.movie_id) as movie_count \n",
    "        FROM Genres g \n",
    "        JOIN Movie_Genre mg ON g.genre_id = mg.genre_id \n",
    "        GROUP BY g.genre_name  \n",
    "        ORDER BY movie_count DESC \n",
    "        LIMIT 5 \n",
    "    \"\"\")\n",
    "    \n",
    "    top_genres = cursor.fetchall() \n",
    "    print(\"- Top 5 genres by movie count:\")\n",
    "    for genre in top_genres:\n",
    "        print(f\" • {genre['genre_name']}: {genre['movie_count']} movies\")\n",
    "    \n",
    "    assert len(top_genres) > 0, \"No genre distribution data found\"\n",
    "\n",
    "    # Test 2: Find highest-rated movies in a specific genre\n",
    "    # Use the first genre from the previous result\n",
    "    target_genre = top_genres[0]['genre_name']\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT m.title, m.vote_average\n",
    "    FROM Movies m \n",
    "    JOIN Movie_Genre mg ON m.id = mg.movie_id \n",
    "    JOIN Genres g ON mg.genre_id = g.genre_id \n",
    "    WHERE g.genre_name = ? \n",
    "        AND m.vote_count > 100 \n",
    "    ORDER BY m.vote_average DESC \n",
    "    LIMIT 5\n",
    "    \"\"\", (target_genre,))\n",
    "\n",
    "    top_rated = cursor.fetchall() \n",
    "    print(f\"\\n- Top 5 highest-rated {target_genre} movies:\")\n",
    "    for movie in top_rated: \n",
    "        print(f\" • {movie['title']} - Rating: {movie['vote_average']}\")\n",
    "\n",
    "    assert len(top_rated) > 0, f\"No highly rated movies found in {target_genre} genre\"\n",
    " \n",
    "    # Test 3: Find genres with highest average ratings\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT g.genre_name, \n",
    "           AVG(m.vote_average) as avg_rating, \n",
    "           COUNT(m.id) as movie_count \n",
    "    FROM Genres g \n",
    "    JOIN Movie_Genre mg ON g.genre_id = mg.genre_id \n",
    "    JOIN Movies m ON mg.movie_id = m.id  \n",
    "    WHERE m.vote_count > 50 \n",
    "    GROUP BY g.genre_name \n",
    "    HAVING movie_count > 10\n",
    "    ORDER BY avg_rating DESC \n",
    "    LIMIT 5\n",
    "    \"\"\")\n",
    "\n",
    "    genres_by_rating = cursor.fetchall() \n",
    "    print(\"\\n Genres with highest average ratings\")\n",
    "    for genre in genres_by_rating: \n",
    "        print(f\" • {genre['genre_name']}: {genre['avg_rating']:.2f} from {genre['movie_count']} movies\")\n",
    "    \n",
    "    assert len(genres_by_rating) > 0, \"No genre rating data found\"\n",
    "\n",
    "def test_actor_and_cast_queries(conn): \n",
    "    \"\"\"Test queries related to actors and movie casts.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    print(\"Testing actor and cast queries:\")\n",
    "\n",
    "    # Test 1: Find actors in most movies \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT c.name, COUNT(DISTINCT mc.movie_id) as movie_count\n",
    "        FROM Cast c\n",
    "        JOIN Movies_Cast mc ON c.actor_id = mc.actor_id \n",
    "        GROUP BY c.name \n",
    "        ORDER BY movie_count DESC \n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "\n",
    "    top_actors = cursor.fetchall() \n",
    "    print(\"- Actors appearing in most movies:\")\n",
    "    for actor in top_actors:\n",
    "        print(f\" • {actor['name']} appears in {actor['movie_count']} movies\")\n",
    "\n",
    "    assert len(top_actors) > 0, \"No actor appearance data found\"\n",
    "\n",
    "    # Test 2: Find a specific actor's filmography\n",
    "    # Use the first actor from previous result\n",
    "    if len(top_actors) > 0:\n",
    "        target_actor = top_actors[0]['name']\n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT m.title, m.release_date \n",
    "            FROM Movies m\n",
    "            JOIN Movies_Cast mc ON m.id = mc.movie_id \n",
    "            JOIN Cast c ON mc.actor_id = c.actor_id\n",
    "            WHERE c.name = ? \n",
    "            ORDER BY m.release_date DESC\n",
    "            LIMIT 10\n",
    "        \"\"\", (target_actor,))\n",
    "\n",
    "        filmography = cursor.fetchall() \n",
    "        print(f\"\\n- Recent filmography for {target_actor:}\")\n",
    "        for movie in filmography:\n",
    "            release_date = movie['release_date'] if movie['release_date'] else \"Unknown date\"\n",
    "            print(f\" • {movie['title']} ({release_date})\")\n",
    "\n",
    "        assert len(filmography) > 0, f\"No filmography found for {target_actor}\"\n",
    "\n",
    "def test_financial_analytics(conn): \n",
    "    \"\"\"Test queries related to financial metrics.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    print(\"Testing financial analytics queries:\")\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT title, budget, revenue, (revenue - budget) as profit, \n",
    "            CASE\n",
    "                WHEN budget > 0 THEN (revenue - budget) * 100 / budget\n",
    "                ELSE NULL\n",
    "            END as roi \n",
    "        FROM Movies\n",
    "        WHERE budget > 1000000 \n",
    "            AND revenue > budget \n",
    "        ORDER BY roi DESC\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "\n",
    "    top_roi_movies = cursor.fetchall() \n",
    "    print(\"- Movies with highest ROI (Return on Investment):\")\n",
    "    for movie in top_roi_movies:\n",
    "        print(f\" • {movie['title']}: ROI {movie['roi']:.1f}% (Budget: ${movie['budget']:,}, Revenue: ${movie['revenue']:,})\")\n",
    "\n",
    "    assert len(top_roi_movies) > 0, \"No ROI data found\"\n",
    "\n",
    "    # Test 2: Find average budget and revenue by decade\n",
    "    # Takes the first 3 characters from the date '2019-05-24' -> '201' \n",
    "    # Adds '0s' to the string '201' + '0s' -> '2010s'\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT\n",
    "            SUBSTR(release_date, 1, 3) || '0s' as decade,\n",
    "            AVG(budget) as avg_budget,\n",
    "            AVG(revenue) as avg_revenue,\n",
    "            COUNT(*) as movie_count\n",
    "        FROM Movies\n",
    "        WHERE release_date IS NOT NULL\n",
    "            AND budget > 0\n",
    "            AND revenue > 0\n",
    "        GROUP BY decade\n",
    "        ORDER BY decade DESC\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "    decades = cursor.fetchall()\n",
    "    print(\"\\n- Average budget and revenue by decade:\")\n",
    "    for decade in decades:\n",
    "        print(f\" • {decade['decade']}: {decade['movie_count']} movies\")\n",
    "        print(f\"   Avg Budget: ${decade['avg_budget']:,.0f}, Avg Revenue: ${decade['avg_revenue']:,.0f}\")\n",
    "\n",
    "    assert len(decades) > 0, \"No decade financial data found\"\n",
    "\n",
    "    # Test 3: Find most expensive movies\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT title, budget, revenue, release_date \n",
    "        FROM Movies\n",
    "        WHERE budget > 0\n",
    "        ORDER BY budget DESC\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "\n",
    "    expensive_movies = cursor.fetchall()\n",
    "    print(\"\\n- Most expensive movies by budget:\")\n",
    "    for movie in expensive_movies: \n",
    "        release_year = movie['release_date'][:4] if movie['release_date'] else \"Unknown\"\n",
    "        print(f\" • {movie['title']} ({release_year}): ${movie['budget']:,}\")\n",
    "\n",
    "    assert len(expensive_movies) > 0, \"No budget data found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070a0b5",
   "metadata": {},
   "source": [
    "# Run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f916d85",
   "metadata": {},
   "source": [
    "### Run Functionality Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "85a16c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test: test_basic_search_functionality\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Testing basic search functionality:\n",
      "Database mode: In-memory sample\n",
      "- Search for 'star' in title: found 1 results\n",
      "  Sample results: Star Wars\n",
      "- Search for 'adventure' in overview: found 4 results\n",
      "  Sample results: Pulp Fiction, WALL·E, Interstellar\n",
      "- Search for 'life' in tagline: found 8 results\n",
      "  Sample results: Gladiator, Once Upon a Time in the West, 12 Angry Men\n",
      "Testing genre filtering for 'Drama' (ID: 6):\n",
      "Found 5 movies in the 'Drama' genre:\n",
      "- Whiplash\n",
      "- One Flew Over the Cuckoo's Nest\n",
      "- Schindler's List\n",
      "- The Green Mile\n",
      "- The Prestige\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_advanced_search_capabilities\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Testing advanced search functionality:\n",
      "- High-rated movies (7.5+) from 2010-2020:\n",
      "  • Interstellar (2014) - Rating: 8.5\n",
      "  • Your Name. (2016) - Rating: 8.5\n",
      "  • Parasite (2019) - Rating: 8.5\n",
      "  • Inception (2010) - Rating: 8.4\n",
      "  • Spider-Man: Into the Spider-Verse (2018) - Rating: 8.4\n",
      "\n",
      "- Movies with budget between $100.0M and $200.0M:\n",
      "  • Dune: Part Two - Budget: $190,000,000.0\n",
      "  • The Dark Knight - Budget: $185,000,000.0\n",
      "  • WALL·E - Budget: $180,000,000.0\n",
      "  • Up - Budget: $175,000,000.0\n",
      "  • Coco - Budget: $175,000,000.0\n",
      "  • Top Gun: Maverick - Budget: $170,000,000.0\n",
      "  • Interstellar - Budget: $165,000,000.0\n",
      "  • Inception - Budget: $160,000,000.0\n",
      "  • Harry Potter and the Prisoner of Azkaban - Budget: $130,000,000.0\n",
      "  • Harry Potter and the Deathly Hallows: Part 2 - Budget: $125,000,000.0\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_genre_based_queries\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Testing genre-based queries:\n",
      "- Top 5 genres by movie count:\n",
      " • Drama: 56 movies\n",
      " • Adventure: 27 movies\n",
      " • Thriller: 24 movies\n",
      " • Crime: 23 movies\n",
      " • Action: 23 movies\n",
      "\n",
      "- Top 5 highest-rated Drama movies:\n",
      " • The Godfather - Rating: 8.7\n",
      " • The Shawshank Redemption - Rating: 8.7\n",
      " • The Godfather Part II - Rating: 8.6\n",
      " • Forrest Gump - Rating: 8.5\n",
      " • The Dark Knight - Rating: 8.5\n",
      "\n",
      " Genres with highest average ratings\n",
      " • Animation: 8.26 from 18 movies\n",
      " • Crime: 8.25 from 23 movies\n",
      " • Drama: 8.22 from 56 movies\n",
      " • Action: 8.22 from 23 movies\n",
      " • Thriller: 8.21 from 24 movies\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_actor_and_cast_queries\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Testing actor and cast queries:\n",
      "- Actors appearing in most movies:\n",
      " • Samuel L. Jackson appears in 5 movies\n",
      " • Robert De Niro appears in 5 movies\n",
      " • Viggo Mortensen appears in 4 movies\n",
      " • Scarlett Johansson appears in 4 movies\n",
      " • Russ Fega appears in 4 movies\n",
      "\n",
      "- Recent filmography for Samuel L. Jackson\n",
      " • Django Unchained (2012-12-25)\n",
      " • Inglourious Basterds (2009-08-02)\n",
      " • Pulp Fiction (1994-09-10)\n",
      " • Jurassic Park (1993-06-11)\n",
      " • GoodFellas (1990-09-12)\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_financial_analytics\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Testing financial analytics queries:\n",
      "- Movies with highest ROI (Return on Investment):\n",
      " • Star Wars: ROI 6949.1% (Budget: $11,000,000.0, Revenue: $775,398,007.0)\n",
      " • The Godfather: ROI 3984.4% (Budget: $6,000,000.0, Revenue: $245,066,411.0)\n",
      " • One Flew Over the Cuckoo's Nest: ROI 3532.7% (Budget: $3,000,000.0, Revenue: $108,981,275.0)\n",
      " • The Empire Strikes Back: ROI 2891.1% (Budget: $18,000,000.0, Revenue: $538,400,000.0)\n",
      " • Pulp Fiction: ROI 2574.1% (Budget: $8,000,000.0, Revenue: $213,928,762.0)\n",
      "\n",
      "- Average budget and revenue by decade:\n",
      " • 2020s: 8 movies\n",
      "   Avg Budget: $100,837,500, Avg Revenue: $601,163,172\n",
      " • 2010s: 14 movies\n",
      "   Avg Budget: $117,833,071, Avg Revenue: $814,149,063\n",
      " • 2000s: 19 movies\n",
      "   Avg Budget: $71,847,368, Avg Revenue: $425,337,970\n",
      " • 1990s: 22 movies\n",
      "   Avg Budget: $34,115,000, Avg Revenue: $277,664,681\n",
      " • 1980s: 10 movies\n",
      "   Avg Budget: $15,630,000, Avg Revenue: $159,988,132\n",
      " • 1970s: 8 movies\n",
      "   Avg Budget: $9,950,000, Avg Revenue: $185,256,415\n",
      " • 1960s: 7 movies\n",
      "   Avg Budget: $3,686,707, Avg Revenue: $25,845,980\n",
      " • 1950s: 5 movies\n",
      "   Avg Budget: $1,746,480, Avg Revenue: $9,286,368\n",
      " • 1940s: 2 movies\n",
      "   Avg Budget: $2,009,864, Avg Revenue: $16,431,062\n",
      " • 1930s: 1 movies\n",
      "   Avg Budget: $1, Avg Revenue: $8,500,000\n",
      " • 1920s: 1 movies\n",
      "   Avg Budget: $92,620,000, Avg Revenue: $650,422\n",
      "\n",
      "- Most expensive movies by budget:\n",
      " • Avengers: Endgame (2019): $356,000,000.0\n",
      " • Avengers: Infinity War (2018): $300,000,000.0\n",
      " • Dune: Part Two (2024): $190,000,000.0\n",
      " • The Dark Knight (2008): $185,000,000.0\n",
      " • WALL·E (2008): $180,000,000.0\n",
      "✅ Test passed!\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_test(test_basic_search_functionality)\n",
    "run_test(test_advanced_search_capabilities)\n",
    "run_test(test_genre_based_queries)\n",
    "run_test(test_actor_and_cast_queries)\n",
    "run_test(test_financial_analytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed48aee",
   "metadata": {},
   "source": [
    "### Run Database Structure and Integrity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6491df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test: test_database_connection\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_query_tables\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Tables in database: [<sqlite3.Row object at 0x00000239F4F7BB50>, <sqlite3.Row object at 0x00000239F4F789D0>, <sqlite3.Row object at 0x00000239F4F7BB80>, <sqlite3.Row object at 0x00000239F4F7B730>, <sqlite3.Row object at 0x00000239F4F7A1A0>, <sqlite3.Row object at 0x00000239F4F7AF20>, <sqlite3.Row object at 0x00000239F4F7B2B0>, <sqlite3.Row object at 0x00000239F4F7B370>, <sqlite3.Row object at 0x00000239F4F7B010>, <sqlite3.Row object at 0x00000239F4F7B4C0>, <sqlite3.Row object at 0x00000239F4F79330>, <sqlite3.Row object at 0x00000239F4F7B6A0>, <sqlite3.Row object at 0x00000239F4F79B10>]\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_all_tables_exist\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Actual tables in database: ['Genres', 'sqlite_sequence', 'Movie_Genre', 'Production_Countries', 'Movie_Production_Countries', 'Movie_Spoken_Languages', 'Keywords', 'Movie_Keywords', 'Spoken_Languages', 'Movies', 'Characters', 'Movies_Cast', 'Cast']\n",
      "ℹ️ INFO: Additional tables found: ['Characters']\n",
      "     These tables are not in the critical or expected lists.\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_movies_table\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_genres_table\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_cast_table\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "⚠️ WARNING: Some expected columns are missing from Cast table: ['characters']\n",
      "ℹ️ INFO: Additional columns found in Cast table: ['popularity', 'biography', 'profile_path']\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_data_integrity\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Data counts: 100 movies, 20 genres, 2217 cast members\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_relationship_integrity\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "✅ All relationship tables have valid foreign keys\n",
      "✅ Test passed!\n",
      "----------------------------------------\n",
      "Running test: test_cardinality\n",
      "Using in-memory test database\n",
      "✅ Imported 20 records into Genres\n",
      "✅ Imported 11005 records into Keywords\n",
      "✅ Imported 89 records into Production_Countries\n",
      "✅ Imported 75 records into Spoken_Languages\n",
      "✅ Imported 100 sample movies\n",
      "✅ Imported 2217 cast members\n",
      "✅ Imported 269 records into Movie_Genre\n",
      "✅ Imported 2467 records into Movies_Cast\n",
      "✅ Imported 2064 records into Movie_Keywords\n",
      "✅ Imported 136 records into Movie_Production_Countries\n",
      "✅ Imported 170 records into Movie_Spoken_Languages\n",
      "Test database ready with 100 movies and 2217 cast members\n",
      "Actors in multiple movies (many-to-many cardinality):\n",
      "- Samuel L. Jackson appears in 5 movies\n",
      "- Robert De Niro appears in 5 movies\n",
      "- Viggo Mortensen appears in 4 movies\n",
      "- Scarlett Johansson appears in 4 movies\n",
      "- Russ Fega appears in 4 movies\n",
      "\n",
      "Movies with multiple genres (many-to-many cardinality):\n",
      "- Puss in Boots: The Last Wish has 5 genres\n",
      "- Inception has 5 genres\n",
      "- Up has 4 genres\n",
      "- Transformers One has 4 genres\n",
      "- Toy Story has 4 genres\n",
      "✅ Test passed!\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_test(test_database_connection)\n",
    "run_test(test_query_tables)\n",
    "run_test(test_all_tables_exist)\n",
    "run_test(test_movies_table)\n",
    "run_test(test_genres_table)\n",
    "run_test(test_cast_table)\n",
    "run_test(test_data_integrity)\n",
    "run_test(test_relationship_integrity)\n",
    "run_test(test_cardinality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
